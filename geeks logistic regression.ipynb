{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ordered-burning",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-320eef081697>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;31m# load the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadCSV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dataset1.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;31m# normalizing feature matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-320eef081697>\u001b[0m in \u001b[0;36mloadCSV\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mfunction\u001b[0m \u001b[0mto\u001b[0m \u001b[0mload\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \t'''\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m                 \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset1.csv'"
     ]
    }
   ],
   "source": [
    "import csv \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "def loadCSV(filename): \n",
    "\t''' \n",
    "\tfunction to load dataset \n",
    "\t'''\n",
    "\twith open(filename,\"r\") as csvfile: \n",
    "\t\tlines = csv.reader(csvfile) \n",
    "\t\tdataset = list(lines) \n",
    "\t\tfor i in range(len(dataset)): \n",
    "\t\t\tdataset[i] = [float(x) for x in dataset[i]]\t \n",
    "\treturn np.array(dataset) \n",
    "\n",
    "\n",
    "def normalize(X): \n",
    "\t''' \n",
    "\tfunction to normalize feature matrix, X \n",
    "\t'''\n",
    "\tmins = np.min(X, axis = 0) \n",
    "\tmaxs = np.max(X, axis = 0) \n",
    "\trng = maxs - mins \n",
    "\tnorm_X = 1 - ((maxs - X)/rng) \n",
    "\treturn norm_X \n",
    "\n",
    "\n",
    "def logistic_func(beta, X): \n",
    "\t''' \n",
    "\tlogistic(sigmoid) function \n",
    "\t'''\n",
    "\treturn 1.0/(1 + np.exp(-np.dot(X, beta.T))) \n",
    "\n",
    "\n",
    "def log_gradient(beta, X, y): \n",
    "\t''' \n",
    "\tlogiszSAXAdqwdetic gradient function \n",
    "\t'''\n",
    "\tfirst_calc = logistic_func(beta, X) - y.reshape(X.shape[0], -1) \n",
    "\tfinal_calc = np.dot(first_calc.T, X) \n",
    "\treturn final_calc \n",
    "\n",
    "\n",
    "def cost_func(beta, X, y): \n",
    "\t''' \n",
    "\tcost function, J \n",
    "\t'''\n",
    "\tlog_func_v = logistic_func(beta, X) \n",
    "\ty = np.squeeze(y) \n",
    "\tstep1 = y * np.log(log_func_v) \n",
    "\tstep2 = (1 - y) * np.log(1 - log_func_v) \n",
    "\tfinal = -step1 - step2 \n",
    "\treturn np.mean(final) \n",
    "\n",
    "\n",
    "def grad_desc(X, y, beta, lr=.01, converge_change=.001): \n",
    "\t''' \n",
    "\tgradient descent function \n",
    "\t'''\n",
    "\tcost = cost_func(beta, X, y) \n",
    "\tchange_cost = 1\n",
    "\tnum_iter = 1\n",
    "\t\n",
    "\twhile(change_cost > converge_change): \n",
    "\t\told_cost = cost \n",
    "\t\tbeta = beta - (lr * log_gradient(beta, X, y)) \n",
    "\t\tcost = cost_func(beta, X, y) \n",
    "\t\tchange_cost = old_cost - cost \n",
    "\t\tnum_iter += 1\n",
    "\t\n",
    "\treturn beta, num_iter \n",
    "\n",
    "\n",
    "def pred_values(beta, X): \n",
    "\t''' \n",
    "\tfunction to predict labels \n",
    "\t'''\n",
    "\tpred_prob = logistic_func(beta, X) \n",
    "\tpred_value = np.where(pred_prob >= .5, 1, 0) \n",
    "\treturn np.squeeze(pred_value) \n",
    "\n",
    "\n",
    "def plot_reg(X, y, beta): \n",
    "\t''' \n",
    "\tfunction to plot decision boundary \n",
    "\t'''\n",
    "\t# labelled observations \n",
    "\tx_0 = X[np.where(y == 0.0)] \n",
    "\tx_1 = X[np.where(y == 1.0)] \n",
    "\t\n",
    "\t# plotting points with diff color for diff label \n",
    "\tplt.scatter([x_0[:, 1]], [x_0[:, 2]], c='b', label='y = 0') \n",
    "\tplt.scatter([x_1[:, 1]], [x_1[:, 2]], c='r', label='y = 1') \n",
    "\t\n",
    "\t# plotting decision boundary \n",
    "\tx1 = np.arange(0, 1, 0.1) \n",
    "\tx2 = -(beta[0,0] + beta[0,1]*x1)/beta[0,2] \n",
    "\tplt.plot(x1, x2, c='k', label='reg line') \n",
    "\n",
    "\tplt.xlabel('x1') \n",
    "\tplt.ylabel('x2') \n",
    "\tplt.legend() \n",
    "\tplt.show() \n",
    "\t\n",
    "\n",
    "\t\n",
    "if __name__ == \"__main__\": \n",
    "\t# load the dataset \n",
    "\tdataset = loadCSV('dataset1.csv') \n",
    "\t\n",
    "\t# normalizing feature matrix \n",
    "\tX = normalize(dataset[:, :-1]) \n",
    "\t\n",
    "\t# stacking columns wth all ones in feature matrix \n",
    "\tX = np.hstack((np.matrix(np.ones(X.shape[0])).T, X)) \n",
    "\n",
    "\t# response vector \n",
    "\ty = dataset[:, -1] \n",
    "\n",
    "\t# initial beta values \n",
    "\tbeta = np.matrix(np.zeros(X.shape[1])) \n",
    "\n",
    "\t# beta values after running gradient descent \n",
    "\tbeta, num_iter = grad_desc(X, y, beta) \n",
    "\n",
    "\t# estimated beta values and number of iterations \n",
    "\tprint(\"Estimated regression coefficients:\", beta) \n",
    "\tprint(\"No. of iterations:\", num_iter) \n",
    "\n",
    "\t# predicted labels \n",
    "\ty_pred = pred_values(beta, X) \n",
    "\t\n",
    "\t# number of correctly predicted labels \n",
    "\tprint(\"Correctly predicted labels:\", np.sum(y == y_pred)) \n",
    "\t\n",
    "\t# plotting regression line \n",
    "\tplot_reg(X, y, beta) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-trainer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
